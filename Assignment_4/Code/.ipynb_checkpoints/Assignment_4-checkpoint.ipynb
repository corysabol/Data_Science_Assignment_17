{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Assignment\n",
    "\n",
    "All of the following are based on data from your project. Each student has to perform analysis on their own no collaboration between team members. Here are the datasets to be analyzed by team datasets:\n",
    "\n",
    "***\n",
    "### ***For Part 1 and 2***\n",
    "\n",
    "##### Library-Computer-Usage-Analysis\n",
    "* Computer Utilization Data by Date-Time\n",
    "\n",
    "##### Volag\n",
    "* Flight Delay Data by Date-Time\n",
    "\n",
    "##### Slipper-Streets\n",
    "* Crash Data by Date-Time\n",
    "\n",
    "##### Corpus\n",
    "* Reviews of Electronic product (laptop) by Date-Time\n",
    "\n",
    "##### SteamConnect\n",
    "* Early Access Score by Release Date-Time\n",
    "\n",
    "##### Toxic-Crusaders\n",
    "* Chemical Industry Release (pick a particular industry) by Date-Time\n",
    "\n",
    "##### Uni-X\n",
    "* Repayment Rate for Female gender by Date-Time\n",
    "\n",
    "##### WRF\n",
    "* Migration count by Date-Time\n",
    "\n",
    "\n",
    "### Part 1\n",
    "\n",
    "* **Conduct Decriptive Analytics (Mean, Median, Quartile) calculation by each division of Date-Time (most probably year or 6 month duration, if you have shorter use 1 month)**\n",
    "* **Calculate divergence of mean and median in your data**\n",
    "* **Visualize the data and draw inferences**\n",
    "\n",
    "### Part 2\n",
    "* **Conduct Probablity distibution analysis based on the data. Analyze your data based on the type of distribution it best fits (for PDF and CDF)**\n",
    "* **Conduct Method of Moments analysis on your data to suggest the best fit distribution. Visualize the results**\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "### ***For Part 3***\n",
    "* Compare with the variable with other variables in your project\n",
    "\n",
    "### Part 3\n",
    "* **Formulate a null hypothesis and evaluate it, perform correlation measures, and construct a linear regression model**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "# it's large enough that it can impact memory signigicantly on my machine (8gb total, would love 32gb)\n",
    "# so let's read it in as chunck and \"lazily\" process things.\n",
    "df = pd.read_csv(os.path.join('..','Data','flights_weather.csv'), chunksize=1000000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some more data wrangling\n",
    "\n",
    "Let's take all the information in the dataframe which represents the date, and then convert it to a single DateTime Object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\datasoup\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (8,9,33,34,35,36,51,52,53,70,71,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = 99\n",
    "\n",
    "'''\n",
    "with open(os.path.join('..','Data','flights_weather_1.csv'), 'w') as f:\n",
    "    for chunk in df:\n",
    "        chunk['DATE'] = pd.to_datetime(\n",
    "            chunk.YEAR*10000+chunk.MONTH*100+chunk.DAY,\n",
    "            format='%Y%m%d'\n",
    "        )\n",
    "        # write chunk to new file\n",
    "        chunk.to_csv(f, mode='a')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can read in the new data set which has a nice neat DateTime object column.\n",
    "dtypes = {\n",
    "    'ORIGIN_AIRPORT': 'str', \n",
    "    'DESTINATION_AIRPORT': 'str', \n",
    "    'IATA_CODE_x': 'str', \n",
    "    'origin_weather_station': 'str', \n",
    "    'IATA_CODE_y': 'str', \n",
    "    'destination_weather_station': 'str', \n",
    "    'OR_MAX': 'str', \n",
    "    'OR_MIN': 'str', \n",
    "    'OR_PRCP': 'str', \n",
    "    'DES_MAX': 'str', \n",
    "    'DES_MIN': 'str', \n",
    "    'DES_PRCP': 'str', \n",
    "    'OR_FRSHTT': 'str', \n",
    "    'DES_FRSHTT': 'str'\n",
    "}\n",
    "path = os.path.join('..','Data','flights_weather_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Our dataset is a little bit large\n",
    "\n",
    "Since our dataset grew to about 2GB in size after merging it with the weather data, it's a bit much to load into\n",
    "the memory of my system and also process. For that reason, a random sample of the dataset should be taken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines = sum(1 for l in open(path))\n",
    "\n",
    "with open(path) as f:\n",
    "    lines = sum(1 for l in f)\n",
    "    \n",
    "# sample ~30% of the dataset\n",
    "sample_size = int(lines / 30)\n",
    "skip = random.sample(range(1,lines), lines - sample_size)\n",
    "# use skip lines\n",
    "sample = pd.read_csv(path, skiprows=skip, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
